# mlfs

Custom-built Python library showcasing key machine learning algorithms implemented from scratch using NumPy. Designed to demonstrate deep understanding of algorithmic foundations, data preprocessing, and model evaluation. Includes detailed performance comparisons with `scikit-learn` for each method.

---

## ğŸš€ Features

* **Linear Regression** (`mlfs.linear_regression.LinearRegression`)
* **Logistic Regression** (`mlfs.logistic_regression.LogisticRegression`)
* **K-Means Clustering** (`mlfs.kmeans.KMeans`)
* **K-Nearest Neighbors** (`mlfs.knn.KNN`)
* **Gaussian Naive Bayes** (`mlfs.naive_bayes.NaiveBayes`)
* **Support Vector Machine** (`mlfs.svm.SVM`)
* **Decision Tree** (`mlfs.decision_tree.DecisionTree`)

Each algorithm is implemented in pure Python/NumPy with no heavy dependencies, so you see exactly how they work under the hood.

---

## ğŸ“‚ Project Structure

```text
mlfs/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ iris.csv
â”‚   â””â”€â”€ breast-cancer.csv
â”œâ”€â”€ mlfs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ linear_regression.py
â”‚   â”œâ”€â”€ logistic_regression.py
â”‚   â”œâ”€â”€ kmeans.py
â”‚   â”œâ”€â”€ knn.py
â”‚   â”œâ”€â”€ naive_bayes.py
â”‚   â”œâ”€â”€ svm.py
â”‚   â”œâ”€â”€ decision_tree.py
â”‚   â”œâ”€â”€ metrics.py
â”‚   â””â”€â”€ preprocessing.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”œâ”€â”€ compare_linear_regression.ipynb
â”‚   â”œâ”€â”€ compare_logistic_regression.ipynb
â”‚   â”œâ”€â”€ compare_kmeans.ipynb
â”‚   â”œâ”€â”€ compare_knn.ipynb
â”‚   â”œâ”€â”€ compare_naive_bayes.ipynb
â”‚   â”œâ”€â”€ compare_svm.ipynb
â”‚   â””â”€â”€ compare_decision_tree.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â””â”€â”€ tests/
    â”œâ”€â”€ .gitkeep
    â”œâ”€â”€ test_linear_regression.py
    â”œâ”€â”€ test_logistic_regression.py
    â”œâ”€â”€ test_kmeans.py
    â”œâ”€â”€ test_knn.py
    â”œâ”€â”€ test_naive_bayes.py
    â”œâ”€â”€ test_svm.py
    â””â”€â”€ test_decision_tree.py
```

---

## ğŸ“¦ Installation

### Prerequisites

* Python â‰¥ 3.8
* (Optional) A virtual environment tool such as `venv` or `conda`

### From PyPI

```bash
pip install mlfs
```

### From Source

```bash
git clone https://github.com/<your-username>/mlfs.git
cd mlfs
pip install -r requirements.txt
pip install -e .
```

---

## âš™ï¸ Usage

### 1. Import your algorithm of choice

```python
from mlfs.linear_regression import LinearRegression
from mlfs.naive_bayes import NaiveBayes
```

### 2. Prepare data

```python
from mlfs.preprocessing import train_test_split, standardize

X, y = ...  # load or generate data
X_train, X_test, y_train, y_test = train_test_split(X, y)
X_train, mean, std = standardize(X_train, return_params=True)
X_test = (X_test - mean) / std
```

### 3. Fit and predict

```python
lr = LinearRegression()
lr.fit(X_train, y_train, iterations=1000)
preds = lr.predict(X_test)

nb = NaiveBayes()
nb.fit(X_train, y_train)
preds = nb.predict(X_test)
```

---

## ğŸ“Š Comparison Notebooks

Use the comparison notebooks to benchmark your implementations against `scikit-learn`:

* `compare_linear_regression.ipynb`
* `compare_logistic_regression.ipynb`
* `compare_kmeans.ipynb`
* `compare_knn.ipynb`
* `compare_naive_bayes.ipynb`
* `compare_svm.ipynb`
* `compare_decision_tree.ipynb`

Run:

```bash
jupyter notebook compare_<algorithm>.ipynb
```

They include performance metrics, timing, and scalability plots.

---

## ğŸ“ Data

Example datasets are stored in `data/`:

* `breast-cancer.csv`
* `iris.csv`

You can replace them with your own datasets as needed.

---

## âœ… Testing

Run all tests:

```bash
pytest
```

Test coverage includes all algorithm modules and metrics implementations.

---

## ğŸ“‘ Requirements

All dependencies are listed in `requirements.txt`, including:

* `numpy`, `pandas`
* `scikit-learn`
* `matplotlib`, `seaborn`, `plotly`
* `pytest`, `memory_profiler`

Install:

```bash
pip install -r requirements.txt
```

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create your feature branch
3. Commit your changes
4. Push the branch
5. Open a PR


