{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6a129d",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "How the algorithm works\n",
    "\n",
    "**We calculate the Euclidean distance between a new sample and all points.**\n",
    "\n",
    "**We determine the label of the sample based on the majority vote.**\n",
    "\n",
    "## Key Points\n",
    "\n",
    "### Euclidean Distance\n",
    "\n",
    "Euclidean distance is defined as the distance between two points, and is given by:\n",
    "\n",
    "$$\n",
    "d(\\mathbf{x}, \\mathbf{y})\n",
    "= \\sqrt{\\sum_{i=0}^{m-1} (x_i - y_i)^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f61c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as SklearnKNN\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from mlfs.knn import KNN as CustomKNN\n",
    "from mlfs.metrics import accuracy as custom_accuracy\n",
    "from mlfs.metrics import balanced_accuracy as custom_balanced_accuracy\n",
    "from mlfs.preprocessing import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea0a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/iris.csv\")\n",
    "df.drop('Id',inplace=True,axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2ca1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Species\"].value_counts().plot.pie(autopct='%1.1f%%', colors=[\"#fefec2\", \"#fe9929\", \"#993404\"], \n",
    "                                       startangle=90, shadow=True)\n",
    "plt.title(\"Species Distribution\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d460ce7",
   "metadata": {},
   "source": [
    "## From this plot we conclude that:\n",
    "\n",
    "**The Data is perfectly balanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feef46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(data=df, x=\"Species\", y=\"SepalLengthCm\", palette=\"YlOrBr\")\n",
    "plt.title(\"Sepal Length by Species\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.histplot(data=df, x=\"SepalLengthCm\", hue=\"Species\", kde=True, palette=\"YlOrBr\", bins=30)\n",
    "plt.title(\"Distribution of Sepal Length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ce3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(data=df, x=\"Species\", y=\"SepalWidthCm\", palette=\"YlOrBr\")\n",
    "plt.title(\"Sepal Width by Species\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.histplot(data=df, x=\"SepalWidthCm\", hue=\"Species\", kde=True, palette=\"YlOrBr\", bins=30)\n",
    "plt.title(\"Distribution of Sepal Width\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecc1d03",
   "metadata": {},
   "source": [
    "### From these plots we conclude that:\n",
    "\n",
    "* **Setosa has much smaller SepalLength than the other 2 classes**\n",
    "\n",
    "* **Virginca has the highest SepalLength, however It seems hard to distingush between Virginca and Versicolor using SepalLength as the difference is less clear**\n",
    "\n",
    "* **We can see that Virginica contains an outlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845d6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(data=df, x=\"Species\", y=\"PetalLengthCm\", palette=\"YlOrBr\")\n",
    "plt.title(\"Petal Length by Species\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.histplot(data=df, x=\"PetalLengthCm\", hue=\"Species\", kde=True, palette=\"YlOrBr\", bins=30)\n",
    "plt.title(\"Distribution of Petal Length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bd0bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.boxplot(data=df, x=\"Species\", y=\"PetalWidthCm\", palette=\"YlOrBr\")\n",
    "plt.title(\"Petal Width by Species\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.histplot(data=df, x=\"PetalWidthCm\", hue=\"Species\", kde=True, palette=\"YlOrBr\", bins=30)\n",
    "plt.title(\"Distribution of Petal Width\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d868ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=df, x=\"SepalLengthCm\", y=\"SepalWidthCm\", hue=\"Species\", size=\"PetalLengthCm\", palette=\"YlOrBr\")\n",
    "plt.title(\"Sepal Dimensions vs. Petal Length\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=df, x=\"PetalLengthCm\", y=\"PetalWidthCm\", hue=\"Species\", size=\"SepalLengthCm\", palette=\"YlOrBr\")\n",
    "plt.title(\"Petal Dimensions vs. Sepal Length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdbb2ba",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "- **Setosa** species have noticeably smaller petals and sepals compared to the other two species.\n",
    "- **Virginica** and **Versicolor** tend to overlap in terms of sepal length and width, making them harder to distinguish based on those features alone.\n",
    "- **PetalLengthCm** and **PetalWidthCm** appear to be the most discriminative features for classification.\n",
    "- **SepalWidthCm** shows the least separation between species and might be less useful on its own.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb768e2",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '\n",
    "\n",
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "155accea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df[\"Species\"]\n",
    "\n",
    "print(df[\"Species\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daee0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a2806",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '\n",
    "\n",
    "# Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_knn_custom_vs_sklearn(X, y, n_repeats=5, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Benchmarks training and prediction times for custom and sklearn KNN implementations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray or pd.DataFrame\n",
    "        Feature matrix.\n",
    "    y : np.ndarray or pd.Series\n",
    "        Target vector.\n",
    "    n_repeats : int\n",
    "        Number of times to repeat the measurement (for averaging).\n",
    "    n_neighbors : int\n",
    "        Number of neighbors to use in KNN.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with average fit and predict times for both models.\n",
    "    \"\"\"\n",
    "\n",
    "    custom_fit_times = []\n",
    "    custom_predict_times = []\n",
    "    sklearn_fit_times = []\n",
    "    sklearn_predict_times = []\n",
    "\n",
    "    for _ in range(n_repeats):\n",
    "        # Custom KNN\n",
    "        model_custom = CustomKNN(n_neighbors=n_neighbors)\n",
    "\n",
    "        start = time.time()\n",
    "        model_custom.fit(X, y)\n",
    "        custom_fit_times.append(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "        model_custom.predict(X)\n",
    "        custom_predict_times.append(time.time() - start)\n",
    "\n",
    "        # sklearn KNN\n",
    "        model_sklearn = SklearnKNN(n_neighbors=n_neighbors)\n",
    "\n",
    "        start = time.time()\n",
    "        model_sklearn.fit(X, y)\n",
    "        sklearn_fit_times.append(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "        model_sklearn.predict(X)\n",
    "        sklearn_predict_times.append(time.time() - start)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Model': ['CustomKNN', 'SklearnKNN'],\n",
    "        'FitTime': [np.mean(custom_fit_times), np.mean(sklearn_fit_times)],\n",
    "        'PredictTime': [np.mean(custom_predict_times), np.mean(sklearn_predict_times)]\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912e3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = benchmark_knn_custom_vs_sklearn(X_train, y_train, n_repeats=5, n_neighbors=5)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de02988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_knn_scalability_vs_sklearn(sample_sizes, n_features=4, n_classes=3, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Benchmarks and compares fit/predict times of custom and sklearn KNN as dataset size increases.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_sizes : list[int]\n",
    "        List of dataset sizes to test.\n",
    "    n_features : int\n",
    "        Number of features per sample.\n",
    "    n_classes : int\n",
    "        Number of output classes.\n",
    "    n_neighbors : int\n",
    "        Number of neighbors for KNN.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with all benchmark results.\n",
    "    \"\"\"\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for n_samples in sample_sizes:\n",
    "        X, y = make_classification(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features,\n",
    "            n_informative=n_features,\n",
    "            n_redundant=0,\n",
    "            n_repeated=0,\n",
    "            n_classes=n_classes,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        custom_model = CustomKNN(n_neighbors=n_neighbors)\n",
    "\n",
    "        start = time.time()\n",
    "        custom_model.fit(X, y)\n",
    "        fit_custom = time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        custom_model.predict(X)\n",
    "        predict_custom = time.time() - start\n",
    "\n",
    "        records.append({\n",
    "            \"Samples\": n_samples,\n",
    "            \"Model\": \"CustomKNN\",\n",
    "            \"FitTime\": fit_custom,\n",
    "            \"PredictTime\": predict_custom\n",
    "        })\n",
    "\n",
    "        sklearn_model = SklearnKNN(n_neighbors=n_neighbors)\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_model.fit(X, y)\n",
    "        fit_sklearn = time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_model.predict(X)\n",
    "        predict_sklearn = time.time() - start\n",
    "\n",
    "        records.append({\n",
    "            \"Samples\": n_samples,\n",
    "            \"Model\": \"SklearnKNN\",\n",
    "            \"FitTime\": fit_sklearn,\n",
    "            \"PredictTime\": predict_sklearn\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    sns.lineplot(data=df, x=\"Samples\", y=\"FitTime\", hue=\"Model\", marker=\"o\", ax=axs[0])\n",
    "    axs[0].set_title(\"Fit Time vs Sample Size\")\n",
    "    axs[0].set_ylabel(\"Time (s)\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    sns.lineplot(data=df, x=\"Samples\", y=\"PredictTime\", hue=\"Model\", marker=\"o\", ax=axs[1])\n",
    "    axs[1].set_title(\"Predict Time vs Sample Size\")\n",
    "    axs[1].set_ylabel(\"Time (s)\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91cf7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [100, 500, 1000, 2000, 5000]\n",
    "df_results = benchmark_knn_scalability_vs_sklearn(sample_sizes)\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b65d1",
   "metadata": {},
   "source": [
    "### üîç Performance Comparison: Custom KNN vs Scikit-learn\n",
    "\n",
    "To evaluate the efficiency and scalability of my own K-Nearest Neighbors (KNN) implementation, I conducted a benchmark against `scikit-learn`'s highly optimized `KNeighborsClassifier`. The comparison included both training (`fit`) and prediction (`predict`) times across datasets of increasing size.\n",
    "\n",
    "#### üìä Observations:\n",
    "\n",
    "- **Training time (fit)** for both models remained very low, as expected for lazy learners like KNN. My custom implementation was extremely fast here, primarily because it performs a simple reference assignment without additional validation or preprocessing.\n",
    "\n",
    "- **Prediction time (predict)** showed a clear divergence:\n",
    "  - The custom KNN implementation exhibited significantly longer prediction times as the dataset grew ‚Äî scaling roughly **quadratically**.\n",
    "  - Scikit-learn's version scaled **much more efficiently**, likely due to its use of optimized Cython code and vectorized distance computations.\n",
    "\n",
    "#### ‚öôÔ∏è Technical Insight:\n",
    "\n",
    "- My implementation uses a basic loop-based approach with manual Euclidean distance calculations and full array sorting via `argsort`.\n",
    "- Scikit-learn leverages optimized data structures (e.g. KD-Trees, Ball Trees) and fast low-level operations, which makes it far more efficient for large-scale datasets.\n",
    "\n",
    "#### ‚úÖ Takeaway:\n",
    "\n",
    "This benchmark highlights the **trade-off between educational clarity and production-level performance**. While my custom KNN was implemented to fully understand the algorithm's inner workings, the scikit-learn version is clearly more suitable for real-world applications involving larger datasets.\n",
    "\n",
    "> ‚ö†Ô∏è Still, building the algorithm from scratch provided valuable insight into the mechanics of instance-based learning and performance bottlenecks ‚Äî an essential step in mastering machine learning fundamentals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48fe936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_knn_accuracy_basic(X_train, X_test, y_train, y_test, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Compares CustomKNN and SklearnKNN using only:\n",
    "    - Custom metrics for CustomKNN\n",
    "    - Sklearn metrics for SklearnKNN\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Comparison of accuracy and balanced accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    custom_model = CustomKNN(n_neighbors=n_neighbors)\n",
    "    custom_model.fit(X_train, y_train)\n",
    "    preds_custom = custom_model.predict(X_test)\n",
    "\n",
    "    acc_custom = custom_accuracy(y_test, preds_custom)\n",
    "    balacc_custom = custom_balanced_accuracy(y_test, preds_custom)\n",
    "\n",
    "    sklearn_model = SklearnKNN(n_neighbors=n_neighbors)\n",
    "    sklearn_model.fit(X_train, y_train)\n",
    "    preds_sklearn = sklearn_model.predict(X_test)\n",
    "\n",
    "    acc_sklearn = accuracy_score(y_test, preds_sklearn)\n",
    "    balacc_sklearn = balanced_accuracy_score(y_test, preds_sklearn)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        \"Model\": [\"CustomKNN\", \"SklearnKNN\"],\n",
    "        \"Accuracy\": [acc_custom, acc_sklearn],\n",
    "        \"Balanced Accuracy\": [balacc_custom, balacc_sklearn]\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a23d44af",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compare_knn_accuracy_basic(X_train, X_test, y_train, y_test)\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv mlfs)",
   "language": "python",
   "name": "mlfs_venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
