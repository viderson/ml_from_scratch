{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2ae5dd",
   "metadata": {},
   "source": [
    "# üîç How Support Vector Machines Work\n",
    "\n",
    "**Support Vector Machines (SVMs) aim to find the optimal decision boundary (hyperplane) that separates data points from two classes in binary classification.**\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ Key Concepts\n",
    "\n",
    "### üìê Hyperplane  \n",
    "A hyperplane is a flat decision boundary that splits the feature space. In an $n$-dimensional space, it's an $(n-1)$-dimensional plane. The ideal hyperplane separates the two classes while keeping the widest possible margin between them.\n",
    "\n",
    "The equation of the hyperplane is:\n",
    "\n",
    "$$\n",
    "w \\cdot x - b = 0\n",
    "$$\n",
    "\n",
    "Where:  \n",
    "- $w$ ‚Äî weight vector (normal to the hyperplane)  \n",
    "- $x$ ‚Äî input feature vector  \n",
    "- $b$ ‚Äî bias term\n",
    "\n",
    "To correctly classify a data point $x_i$ with label $y_i \\in \\{-1, 1\\}$, SVM requires:\n",
    "\n",
    "$$\n",
    "y_i (w \\cdot x_i - b) \\geq 1\n",
    "$$\n",
    "\n",
    "This means points are not only correctly classified but also lie outside the margin.\n",
    "\n",
    "---\n",
    "\n",
    "### üìè Margin and Support Vectors  \n",
    "The **margin** is the distance between the hyperplane and the closest data points from either class ‚Äî these critical points are known as **support vectors**.\n",
    "\n",
    "A larger margin typically leads to better generalization. SVM tries to **maximize this margin** while correctly classifying the training data (or minimizing the error when using soft margins).\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Gradient Update Rules\n",
    "\n",
    "The optimization objective combines:\n",
    "- Margin maximization (via minimizing $\\|w\\|^2$),\n",
    "- Regularization (to prevent overfitting),\n",
    "- and penalty for misclassified/marginal points.\n",
    "\n",
    "Let $\\lambda$ be the regularization strength.\n",
    "\n",
    "If a data point is **correctly classified and outside the margin** ($y_i(w \\cdot x_i - b) \\geq 1$):\n",
    "\n",
    "- Gradient w.r.t. weights:  \n",
    "  $$\n",
    "  \\frac{\\partial J}{\\partial w} = 2\\lambda w\n",
    "  $$\n",
    "- Gradient w.r.t. bias:  \n",
    "  $$\n",
    "  \\frac{\\partial J}{\\partial b} = 0\n",
    "  $$\n",
    "\n",
    "If a data point is **misclassified or within the margin** ($y_i(w \\cdot x_i - b) < 1$):\n",
    "\n",
    "- Gradient w.r.t. weights:  \n",
    "  $$\n",
    "  \\frac{\\partial J}{\\partial w} = 2\\lambda w - y_i x_i\n",
    "  $$\n",
    "- Gradient w.r.t. bias:  \n",
    "  $$\n",
    "  \\frac{\\partial J}{\\partial b} = -y_i\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340d363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC as SklearnSVM\n",
    "\n",
    "from mlfs.svm import SVM as CustomSVM\n",
    "from mlfs.preprocessing import train_test_split, standardize\n",
    "from mlfs.metrics import (\n",
    "    accuracy as custom_accuracy,\n",
    "    precision as custom_precision,\n",
    "    recall as custom_recall,\n",
    "    f1_score as custom_f1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ca33d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/breast-cancer.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98625467",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '\n",
    "\n",
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9af4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2cb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = (df['diagnosis'] == 'M').astype(int)\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(corr, cmap='viridis_r',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542d3d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "notincluded_columns = abs(corr['diagnosis'])[abs(corr['diagnosis'] < 0.25)]\n",
    "notincluded_columns = notincluded_columns.index.tolist()\n",
    "for col in notincluded_columns:\n",
    "  df.drop(col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa8ad90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diagnosis', axis = 1).values\n",
    "y = df['diagnosis']\n",
    "print('Shape of X', X.shape)\n",
    "print('Shape of y', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10928f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "X_train, mean, std = standardize(X_train, return_params=True)\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1929b1b",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '\n",
    "\n",
    "# Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65171831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_svm_custom_vs_sklearn(X, y, n_repeats=5, iterations=1000, lr=0.01, lambdaa=0.01):\n",
    "    \"\"\"\n",
    "    Benchmarks training and prediction times for custom and sklearn SVM implementations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray\n",
    "        Feature matrix.\n",
    "    y : np.ndarray\n",
    "        Target vector (binary: 0/1).\n",
    "    n_repeats : int\n",
    "        Number of repetitions for averaging time.\n",
    "    iterations : int\n",
    "        Number of training epochs for the custom SVM.\n",
    "    lr : float\n",
    "        Learning rate for the custom SVM.\n",
    "    lambdaa : float\n",
    "        Regularization parameter for the custom SVM.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with average fit and predict times for both models.\n",
    "    \"\"\"\n",
    "\n",
    "    custom_fit_times = []\n",
    "    custom_predict_times = []\n",
    "    sklearn_fit_times = []\n",
    "    sklearn_predict_times = []\n",
    "\n",
    "    for _ in range(n_repeats):\n",
    "        # Custom SVM\n",
    "        model_custom = CustomSVM(iterations=iterations, lr=lr, lambdaa=lambdaa)\n",
    "\n",
    "        start = time.time()\n",
    "        model_custom.fit(X, y)\n",
    "        custom_fit_times.append(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "        model_custom.predict(X)\n",
    "        custom_predict_times.append(time.time() - start)\n",
    "\n",
    "        # Sklearn SVM\n",
    "        model_sklearn = SklearnSVM(kernel='linear')\n",
    "\n",
    "        start = time.time()\n",
    "        model_sklearn.fit(X, y)\n",
    "        sklearn_fit_times.append(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "        model_sklearn.predict(X)\n",
    "        sklearn_predict_times.append(time.time() - start)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Model': ['CustomSVM', 'SklearnSVM'],\n",
    "        'FitTime': [np.mean(custom_fit_times), np.mean(sklearn_fit_times)],\n",
    "        'PredictTime': [np.mean(custom_predict_times), np.mean(sklearn_predict_times)]\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b585efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = benchmark_svm_custom_vs_sklearn(X_train, y_train)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19f65572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_svm_scalability_vs_sklearn(sample_sizes, n_features=4, iterations=1000, lr=0.01, lambdaa=0.01):\n",
    "    \"\"\"\n",
    "    Benchmarks and compares fit/predict times of custom and sklearn SVM as dataset size increases.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_sizes : list[int]\n",
    "        List of dataset sizes to test.\n",
    "    n_features : int\n",
    "        Number of features per sample.\n",
    "    iterations : int\n",
    "        Number of training iterations for the custom SVM.\n",
    "    lr : float\n",
    "        Learning rate for custom SVM.\n",
    "    lambdaa : float\n",
    "        Regularization parameter for custom SVM.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with all benchmark results.\n",
    "    \"\"\"\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for n_samples in sample_sizes:\n",
    "        X, y = make_classification(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features,\n",
    "            n_informative=n_features,\n",
    "            n_redundant=0,\n",
    "            n_classes=2,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Custom SVM\n",
    "        custom_model = CustomSVM(iterations=iterations, lr=lr, lambdaa=lambdaa)\n",
    "\n",
    "        start = time.time()\n",
    "        custom_model.fit(X, y)\n",
    "        fit_custom = time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        custom_model.predict(X)\n",
    "        predict_custom = time.time() - start\n",
    "\n",
    "        records.append({\n",
    "            \"Samples\": n_samples,\n",
    "            \"Model\": \"CustomSVM\",\n",
    "            \"FitTime\": fit_custom,\n",
    "            \"PredictTime\": predict_custom\n",
    "        })\n",
    "\n",
    "        # Sklearn SVM\n",
    "        sklearn_model = SklearnSVM(kernel='linear')\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_model.fit(X, y)\n",
    "        fit_sklearn = time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_model.predict(X)\n",
    "        predict_sklearn = time.time() - start\n",
    "\n",
    "        records.append({\n",
    "            \"Samples\": n_samples,\n",
    "            \"Model\": \"SklearnSVM\",\n",
    "            \"FitTime\": fit_sklearn,\n",
    "            \"PredictTime\": predict_sklearn\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    sns.lineplot(data=df, x=\"Samples\", y=\"FitTime\", hue=\"Model\", marker=\"o\", ax=axs[0])\n",
    "    axs[0].set_title(\"Fit Time vs Sample Size\")\n",
    "    axs[0].set_ylabel(\"Time (s)\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    sns.lineplot(data=df, x=\"Samples\", y=\"PredictTime\", hue=\"Model\", marker=\"o\", ax=axs[1])\n",
    "    axs[1].set_title(\"Predict Time vs Sample Size\")\n",
    "    axs[1].set_ylabel(\"Time (s)\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f400c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [100, 500, 1000, 2000, 5000]\n",
    "benchmark_df = benchmark_svm_scalability_vs_sklearn(sample_sizes)\n",
    "print(benchmark_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ade4be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_svm_accuracy_basic(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Compares CustomSVM and SklearnSVM using classification metrics:\n",
    "    - accuracy\n",
    "    - precision\n",
    "    - recall\n",
    "    - f1_score\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Comparison of all metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # Custom SVM\n",
    "    custom_model = CustomSVM()\n",
    "    custom_model.fit(X_train, y_train)\n",
    "    preds_custom = custom_model.predict(X_test)\n",
    "\n",
    "    acc_custom = custom_accuracy(y_test, preds_custom)\n",
    "    prec_custom = custom_precision(y_test, preds_custom)\n",
    "    rec_custom = custom_recall(y_test, preds_custom)\n",
    "    f1_custom = custom_f1(y_test, preds_custom)\n",
    "\n",
    "    # Sklearn SVM\n",
    "    sklearn_model = SklearnSVM(kernel='linear')\n",
    "    sklearn_model.fit(X_train, y_train)\n",
    "    preds_sklearn = sklearn_model.predict(X_test)\n",
    "\n",
    "    acc_sklearn = accuracy_score(y_test, preds_sklearn)\n",
    "    prec_sklearn = precision_score(y_test, preds_sklearn)\n",
    "    rec_sklearn = recall_score(y_test, preds_sklearn)\n",
    "    f1_sklearn = f1_score(y_test, preds_sklearn)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        \"Model\": [\"CustomSVM\", \"SklearnSVM\"],\n",
    "        \"Accuracy\": [acc_custom, acc_sklearn],\n",
    "        \"Precision\": [prec_custom, prec_sklearn],\n",
    "        \"Recall\": [rec_custom, rec_sklearn],\n",
    "        \"F1 Score\": [f1_custom, f1_sklearn]\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed561fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compare_svm_accuracy_basic(X_train, X_test, y_train, y_test)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012fc63",
   "metadata": {},
   "source": [
    "## üîç Summary: Comparison of Custom SVM vs. Scikit-learn SVM\n",
    "\n",
    "### ‚úÖ Accuracy and Classification Metrics\n",
    "\n",
    "| Model        | Accuracy | Precision | Recall | F1 Score |\n",
    "|--------------|----------|-----------|--------|----------|\n",
    "| CustomSVM    | 0.9646   | **1.0000** | 0.8947 | 0.9444   |\n",
    "| SklearnSVM   | 0.9646   | 0.9722    | **0.9211** | **0.9459** |\n",
    "\n",
    "- Both implementations achieve identical overall accuracy on the test set.\n",
    "- CustomSVM exhibits perfect precision (no false positives), but slightly lower recall.\n",
    "- SklearnSVM strikes a better balance between precision and recall, leading to a higher F1 score.\n",
    "\n",
    "---\n",
    "\n",
    "### üïí Execution Time\n",
    "\n",
    "| Samples | Model        | Fit Time (s) | Predict Time (s) |\n",
    "|---------|--------------|---------------|------------------|\n",
    "| 100     | CustomSVM    | 0.76          | 0.00003          |\n",
    "| 100     | SklearnSVM   | **0.0018**     | 0.00032          |\n",
    "| 5000    | CustomSVM    | 35.85         | 0.00009          |\n",
    "| 5000    | SklearnSVM   | **1.59**       | **0.20**         |\n",
    "\n",
    "- Scikit-learn‚Äôs implementation is significantly faster during both training and inference.\n",
    "- The custom SVM uses a full stochastic gradient descent loop with manual hinge loss updates, which results in much slower training, especially on larger datasets.\n",
    "- SklearnSVM leverages highly optimized C libraries (e.g., `liblinear`), allowing for much better performance and scalability.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öñÔ∏è Conclusion\n",
    "\n",
    "- The custom implementation produces comparable accuracy but is much less efficient computationally.\n",
    "- While it performs well in terms of precision, the lower recall indicates room for improvement in decision boundary flexibility or learning rate tuning.\n",
    "- Scikit-learn remains the preferred choice for real-world applications due to its optimization and speed, but the custom SVM serves as a solid educational baseline for understanding the underlying mechanics of margin-based classifiers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv mlfs)",
   "language": "python",
   "name": "mlfs_venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
