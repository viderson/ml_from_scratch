{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57c440d",
   "metadata": {},
   "source": [
    "# Decision Tree  \n",
    "## How the Algorithm Works\n",
    "\n",
    "**The process begins with all examples placed at the root node. Then:**\n",
    "\n",
    "- **For each available feature, we calculate the information gain and select the one with the highest value.**  \n",
    "- **We split the dataset based on the selected feature.**  \n",
    "- **This process repeats recursively until a stopping condition is met.**\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Entropy  \n",
    "\n",
    "**Entropy is a measure of impurity or disorder in a dataset.**  \n",
    "\n",
    "Entropy formula:\n",
    "$$\n",
    "H = -\\sum p_i \\log_2 p_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $p_i$ — the proportion of examples belonging to class $i$ in the node.\n",
    "\n",
    "---\n",
    "\n",
    "### Information Gain\n",
    "\n",
    "**Information gain measures the reduction in entropy after a dataset is split.**  \n",
    "**We aim to choose the split that results in the highest information gain.**\n",
    "\n",
    "Formula:\n",
    "$$\n",
    "\\text{Information Gain} = H(\\text{parent}) - \\left( w_\\text{left} \\cdot H(\\text{left}) + w_\\text{right} \\cdot H(\\text{right}) \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $H(\\text{parent})$ — entropy of the node before the split  \n",
    "- $H(\\text{left})$, $H(\\text{right})$ — entropies of the left and right branches  \n",
    "- $w_\\text{left}$, $w_\\text{right}$ — proportions of examples in the left and right branches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d66bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9d7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTree\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "from mlfs.decision_tree import DecisionTree as CustomDecisionTree\n",
    "from mlfs.metrics import (\n",
    "    accuracy as custom_accuracy,\n",
    "    balanced_accuracy as custom_balanced_accuracy\n",
    ")\n",
    "\n",
    "from mlfs.preprocessing import train_test_split, standardize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93892c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/breast-cancer.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4093d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da79914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['diagnosis'].value_counts()\n",
    "labels = ['Benign', 'Malignant']\n",
    "sizes = [class_counts[0], class_counts[1]]\n",
    "colors = ['#99ff99','#339933']\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=140)\n",
    "plt.title('Diagnosis Distribution')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158d2b52",
   "metadata": {},
   "source": [
    "## From this plot we conclude that:\n",
    "* **Data isn't balanced, accuracy wont be a good evaluation metric for this dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a730a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "features = df.columns[1:6]  \n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 5))\n",
    "\n",
    "for i, col in enumerate(features):\n",
    "    sns.boxplot(x='diagnosis', y=col, data=df, ax=axes[i], palette=\"Set2\")\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel('')\n",
    "\n",
    "fig.suptitle(\"Boxplots for Selected Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970bfa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in  df.drop('diagnosis',axis=1).columns[5:10]:\n",
    "    fig = px.scatter(data_frame=df,color='diagnosis',x=column,color_discrete_sequence=['#007500','#5CFF5C'],)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d918ae5",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '\n",
    "\n",
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0232b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = (df['diagnosis'] == 'M').astype(int)\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(corr, cmap='viridis_r',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269abb25",
   "metadata": {},
   "source": [
    "## From this plot we conclude that:\n",
    "* **Some features aren't correlated with the target maybe we should remove them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed2803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "notincluded_columns = abs(corr['diagnosis'])[abs(corr['diagnosis'] < 0.25)]\n",
    "notincluded_columns = notincluded_columns.index.tolist()\n",
    "for col in notincluded_columns:\n",
    "  df.drop(col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e64a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(notincluded_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68cbf3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diagnosis', axis = 1).values\n",
    "y = df['diagnosis']\n",
    "print('Shape of X', X.shape)\n",
    "print('Shape of y', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4afe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "X_train, mean, std = standardize(X_train, return_params=True)\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5858f",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '\n",
    "\n",
    "# Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6a0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_decision_tree_custom_vs_sklearn(X, y, n_repeats=5):\n",
    "    \"\"\"\n",
    "    Benchmarks training and prediction times for custom and sklearn decision tree implementations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : np.ndarray or pd.DataFrame\n",
    "        Feature matrix.\n",
    "    y : np.ndarray or pd.Series\n",
    "        Target vector.\n",
    "    n_repeats : int\n",
    "        Number of times to repeat the measurement (for averaging).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with average fit and predict times for both models.\n",
    "    \"\"\"\n",
    "\n",
    "    custom_fit_times = []\n",
    "    custom_predict_times = []\n",
    "    sklearn_fit_times = []\n",
    "    sklearn_predict_times = []\n",
    "\n",
    "    for _ in range(n_repeats):\n",
    "        custom_model = CustomDecisionTree(min_samples=2, max_depth=5)\n",
    "\n",
    "        start = time.time()\n",
    "        custom_model.fit(X, y)\n",
    "        custom_fit_times.append(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "        custom_model.predict(X)\n",
    "        custom_predict_times.append(time.time() - start)\n",
    "\n",
    "        sklearn_model = SklearnDecisionTree(max_depth=5)\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_model.fit(X, y)\n",
    "        sklearn_fit_times.append(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "        sklearn_model.predict(X)\n",
    "        sklearn_predict_times.append(time.time() - start)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Model': ['CustomDecisionTree', 'SklearnDecisionTree'],\n",
    "        'FitTime': [np.mean(custom_fit_times), np.mean(sklearn_fit_times)],\n",
    "        'PredictTime': [np.mean(custom_predict_times), np.mean(sklearn_predict_times)]\n",
    "    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d45afe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = benchmark_decision_tree_custom_vs_sklearn(X_train, y_train)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e0dfb",
   "metadata": {},
   "source": [
    "### Benchmark Results: Custom vs Sklearn Decision Tree\n",
    "\n",
    "\n",
    "#### Analysis\n",
    "\n",
    "- **Training Time**: The custom implementation, written from scratch in Python, naturally incurs higher training time compared to scikit-learn’s optimized C-based backend. This trade-off is expected in educational or prototype implementations that prioritize clarity and algorithmic transparency over raw performance.\n",
    "\n",
    "- **Prediction Time**: While also slightly higher in the custom version, the prediction step remains fast and efficient for typical dataset sizes.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "This benchmark highlights the performance differences between a reference implementation and a production-grade library. The custom decision tree was developed to deepen understanding of core decision tree logic and data structures, and serves as a solid foundation for future optimization work. Despite the performance gap, the implementation demonstrates correctness and functional parity with sklearn’s API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c30e3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_varying_sample_sizes(sample_sizes, n_features=20, n_classes=2, n_repeats=3):\n",
    "    all_results = []\n",
    "\n",
    "    for n_samples in sample_sizes:\n",
    "        print(f\"Benchmarking for {n_samples} samples...\")\n",
    "        X, y = make_classification(n_samples=n_samples,\n",
    "                                   n_features=n_features,\n",
    "                                   n_informative=int(n_features * 0.6),\n",
    "                                   n_redundant=int(n_features * 0.2),\n",
    "                                   n_classes=n_classes,\n",
    "                                   random_state=42)\n",
    "        results = benchmark_decision_tree_custom_vs_sklearn(X, y, n_repeats=n_repeats)\n",
    "        results['sample_size'] = n_samples\n",
    "        all_results.append(results)\n",
    "\n",
    "    df = pd.concat(all_results, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def plot_benchmark_results(df):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.lineplot(data=df, x='sample_size', y='FitTime', hue='Model', marker='o')\n",
    "    plt.title('Training Time vs Number of Samples')\n",
    "    plt.xlabel('Number of Samples')\n",
    "    plt.ylabel('Average Training Time [s]')\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.lineplot(data=df, x='sample_size', y='PredictTime', hue='Model', marker='o')\n",
    "    plt.title('Prediction Time vs Number of Samples')\n",
    "    plt.xlabel('Number of Samples')\n",
    "    plt.ylabel('Average Prediction Time [s]')\n",
    "    plt.xscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "sample_sizes = [100, 500, 1000, 5000, 10000]\n",
    "df_results = benchmark_varying_sample_sizes(sample_sizes, n_features=20, n_classes=2, n_repeats=3)\n",
    "plot_benchmark_results(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8350aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = CustomDecisionTree(min_samples=2, max_depth=5)\n",
    "custom_model.fit(X_train, y_train)\n",
    "\n",
    "sk_model = SklearnDecisionTree(max_depth=5)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_custom = custom_model.predict(X_test)\n",
    "y_pred_sk     = sk_model.predict(X_test)\n",
    "\n",
    "y_true = np.array(y_test).ravel()\n",
    "\n",
    "acc_c  = custom_accuracy(y_true, y_pred_custom)\n",
    "balacc_c = custom_balanced_accuracy(y_true, y_pred_custom)\n",
    "\n",
    "acc_s  = accuracy_score(y_true, y_pred_sk)\n",
    "balacc_s = balanced_accuracy_score(y_true, y_pred_sk)\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'Model':            ['Custom',       'Sklearn'],\n",
    "    'Accuracy':         [acc_c,          acc_s],\n",
    "    'Balanced Accuracy':[balacc_c,       balacc_s]\n",
    "})\n",
    "\n",
    "display(df_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv mlfs)",
   "language": "python",
   "name": "mlfs_venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
